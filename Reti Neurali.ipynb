{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reti Neurali: bit-by-bit\n",
    "\n",
    "## Introduzione\n",
    "\n",
    "In questo articolo andreamo ad implementare da zero una rete neurale, ma prima di sporcarci le mani dobbiamo chiarire che cos'è una rete neurale e quando ha senso utilizzarla.\n",
    "\n",
    "Una rete neurale può essere vista sotto due punti di vista, uno matematico e uno biologico. Mentre il punto di vista matematico chiarirà perché utilizzare le reti neurali, quello biologico permettera invece di comprenderne l'implementazione.\n",
    "\n",
    "Matematicamente una rete neurale può essere definita come un approssimatore universale, cioè una rete neurale$^1$ è capace di approssimare con una precisione arbitraria una qualsiasi$^2$ funzione $f$, sufficentemente regolare, che prende in input un insieme di valori reali e da in output un altro insieme di valori reali. Questo chiarisce perché le reti neurali sono utili: se abbiamo un insieme di coppie input-output e sappiamo che esiste una relazione tra quei valori, ma non siamo capaci di comprendere quale sia questa relazione, allora una rete neurale potrebbe aiutarci! Una rete neurale, infatti, ricerca pattern tra i dati che le diamo in pasto, andando a cercare cioè degli schemi che leghino le informazioni che le sottoponiamo.\n",
    "\n",
    "Come si intuisce dal nome, le reti neurali sono strettamente legate alla biologia, possono essere infatti definite come un modello computazionale ispirato dal funzionamento delle reti neurali biologiche. Ed è da questo punto che inizieremo.\n",
    "\n",
    "## Le reti neurali biologiche\n",
    "Per comprendere il funzionamento delle reti neurali artificiali è opportuno prima avere una visione di come funzionano le reti neurali biologiche, anche se quella che verrà data è solo una estrema semplificazione, ma utile per i nostri scopi.\n",
    "\n",
    "### Il neurone\n",
    "\n",
    "Una rete neurale biologica è formata da moltissimi neuroni interconnessi tra di loro, dunque ha senso iniziare questa overview partendo dalla struttura del neurone biologico, che possiamo suddividere in tre parti principali:\n",
    "- Soma: è la parte centrale del neurone, si occupa di elaborare gli input in ingresso e generare un output in uscita\n",
    "- Dendriti: sono delle ramificazioni del neurone e permettono a questo di interagire con gli altri neuroni. Sono i dendriti che ricevono gli input\n",
    "- Assone: è un prolungamento del neurone, la sua funzione è trasmettere l'output\n",
    "\n",
    "Ora che abbiamo visto come sono composti i neuroni, possiamo comprender come questi interagiscano tra di loro: gli input di un neurone possono provenire da altri neuroni o direttamente dall'esterno. Dunque l'output di un neurone, insieme a quello di molti altri, diventerà l'input di un altro neurone che, dopo aver elaborato tutti gli input ricevuti, genererà un output che a sua volta diverrà parte dell'input di molti altri neuroni e così via...\n",
    "\n",
    "![Neurone](neurone.jpg)\n",
    "\n",
    "Anche se biologicamente non è sempre vero, per i nostri scopi possiamo immaginare come le uniche interconnessioni possibili tra neuroni siano quelle tra assoni e dendriti.\n",
    "\n",
    "### L'apprendimento\n",
    "\n",
    "Ora abbiamo bisogno solamente di un ultimo pezzo: com'è possibile l'apprendimento? Com'è possibile, dunque, che delle reti di neuroni possano apprendere comportamenti sempre nuovi?\n",
    "\n",
    "Le reti neurali biologiche non sono reti statiche ma dinamiche, la loro struttura, infatti, cambia in continuazione: più nel dettaglio sono le connessioni tra dendriti ed assone, dette sinapsi, a variare. Infatti quando un neurone trasmette, mediante il suo assone, un output questo non viene ricevuto dal dendrite di un altro neurone esattamente come è stato generato ma giunge al dendrite attraverso una sinapsi, che può indebolire o rafforzare il segnale. L'apprendimento a livello cerebrale avviene non solo creando od eliminando nuove connessioni tra neuroni ma anche rafforzando o indebolendo quelle già esistenti.\n",
    "\n",
    "Adesso abbiamo tutti gli strumenti per comprendere come creare un modello computazionale di una rete neurale biologica.\n",
    "\n",
    "## Il percettrone\n",
    "\n",
    "Così come già fatto per le reti neurali biologiche, la nostra modellizzazione inizia proprio dal creare un modello matematico del neurone artificiale, anche detto percettrone.\n",
    "\n",
    "Possiamo definire il percettrone come una funzione matematica che prende in input un vettore di numeri reali $I$ e restituisce un valore reale $O$; un vettore altro non è che una lista ordinata, cioè una lista in cui l'ordine con cui vengono elencati gli elementi è importante e non può essere variato.\n",
    "\n",
    "Dunque formalmente $f(I) = O$. Ma che cosa viene fatto nello specifico dentro $f$? L'elaborazione può essere divisa in due passi:\n",
    "\n",
    "##### Passo 1 \n",
    "Il vettore di input $I$ viene moltiplicato per un vettore $W$ , detto vettore dei pesi. Moltiplicare un vettore per un altro significa semplicemente che il primo elemento di $I$ viene moltiplicato con il primo elemento di $W$, il secondo con il secondo e così via, infine i prodotti così ottenuti vengono sommati tra di loro: quello che stiamo facendo è moltiplicare dunque un input con il suo rispettivo peso, proprio come nei neuroni ogni input viene modificato (rinforzato o indebolito) da una sinapsi, in questo caso il compito della sinapsi vine svolto dal peso. Bisogna solo ricordarsi è che il numero di elementi dei due vettori, detto dimensione, deve essere, ovviamente, uguale. \n",
    "\n",
    "Formalmente: $$\\sum_{i=1}^{n} I_i*W_i $$ Dove $n$ è la dimensione del vettore degli input o equivalentemente del vettore dei pesi.\n",
    "\n",
    "In python:\n",
    "\n",
    "```python\n",
    "def molt(I, W):\n",
    "    res = 0\n",
    "    for i in range(len(I)):\n",
    "        res += I[i]*W[i]\n",
    "    return res\n",
    "```\n",
    "\n",
    "##### Passo 2\n",
    "Al risultato della moltiplicazione tra vettori, detta anche somma pesata, viene applicata una funzione $g$, detta funzione di soglia o di attivazione: il suo compito è quello di regolare l'attivazione del neurone, elaborando la somma pesata attraverso una funzione, di solito, non lineare$^3$. L'output, quindi, non sarà la sola somma pesata degli input. Ma che significa regolare l'attivazione? Una funzione di attivazione mappa la somma pesata in un intervallo di valori significativi: solitamente come output di un neurone abbiamo bisogno di ricevere valori nell'intervallo (-1;1) o (0;1), ma nulla ci assicura che dalla somma pesata escano valori di questo tipo, dunque la funzione di attivazione converte il valore che riceve in un valore nell'intervallo desiderato. Quale funzione e quindi anche intervallo usare dipende dal problema che stiamo affrontando: se l'output è una probabilità useremo l'intervallo (0;1), in altri casi ci servirà un intervallo con anche valori negativi (-1;1); ma anche dopo aver scelto un intervallo bisogna studiare quale funzione usare, infatti vi sono funzioni diverse che mappano nello stesso intervallo.  La funzione di attivazione è detta anche di soglia perchè, storicamente, la prima funzione ad essere utilizzata fu la funzione di Heaviside, detta anche funzione a gradino, che fungeva,appunto, da soglia: \"attiva\" il neurone, restituisce 1, solo se la somma pesata è positiva, altrimenti restituisce 0.\n",
    "\n",
    "![Funzione di Heaviside](gradino.png)\n",
    "\n",
    "Di seguito, invece, alcuni esempi delle funzioni di attivazione più utilizzate:\n",
    "\n",
    "![Funzioni](fun.png)\n",
    "\n",
    "Per riassumere, dunque, matematicamente quello che fa un Percettrome è: $f(I) = g( I*W ) = O$ che equivale a fare $f(I) = g( \\sum_{i=1}^{n} I_i*W_i ) = O$:\n",
    "\n",
    "![Percettrone](percettrone.png)\n",
    "\n",
    "Nell'immagine il simbolo $\\sum$ indica la somma dei singoli elementi pesati, cioè moltiplicati con il rispettivo peso.\n",
    "\n",
    "Dopo aver modellizzato il percettrone rimane da darne una definizione dal punto di vista computazionale: un Percettrone è un classificatore binario lineare. Analizziamo una parola alla volta:\n",
    "\n",
    "- Classificatore: un classificatore è un particolare algoritmo che fissato un insieme di \"classi\" diverse, decide, dato un input, a quale classe quell'input appartiene. Quello che fa  è dunque fissato un elemento, decidere a quale gruppo appartiene tra i possibili.\n",
    "\n",
    "- Binario: è un classificatore che riesce a distinguere solo tra due classi diverse.\n",
    "\n",
    "- Lineare: il concetto di linearità è piuttosto complesso, quello che noi andremo ad approfondire è ciò che si intende per classificatore binario lineare. Un classificatore binario si dice lineare se è capace di dividere uno spazio vettoriale $V$ solo attraverso uno ed un solo iperpiano$^4$ $H$: distinguendo quindi i punti che si trovano da un lato o dall'altro di $H$. Daremo per chiarezza una spiegazione più pratica considerando uno spazio bidimensionale: in questo caso un iperpiano altro non è che una retta, dunque un classificatore binario lineare è un algoritmo che divide lo spazio, cioè il piano, attraverso un una retta, distinguendo quindi i punti da un lato o dall'altro della retta:\n",
    "\n",
    "![Classificatore](classificatore.png)\n",
    "\n",
    "![Lineare-Non Lineare](lineare-non.png)\n",
    "\n",
    "Un percettrone apprende andando a modificare input dopo input i suoi pesi che, geometricamente, rappresentano la posizione dell'iperpiano:\n",
    "\n",
    "![Apprendimento](learning.png)\n",
    "\n",
    "Dati due classificatori che lavorano su uno stesso problema, il migliore si trova verificando quale tra i due commette meno errori.\n",
    "\n",
    "![Multi](lineare.png)\n",
    "\n",
    "Nell'immagine sopra abbiamo tre classificatori binari lineari: mentre sia il blu che il rosso sono validi, riescono cioè a distinguere correttamente tutti gli input, quello verde non ci riesce dunque non è un buon classificatore rispetto agli altri due. Ma tra il verde e il rosso possiamo individuarne uno migliore di un altro? In questo caso è possibile, il migliore tra i due è il rosso perché è quello più distante da entrambi i gruppi, questa caratteristica può essere utile, perchè solitamente,ci rende più sicuri del fatto che un nuovo input venga classificato correttamente, ad esempio: il blu è molto più vicino al gruppo nero rispetto al rosso, questo vuol dire che un nuovo elemento bero che si discosti di poco dal suo gruppo rischia di essere classificato male dal blu, ma è difficile che questo accada con il rosso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementazione\n",
    "Di seguito andremo ad implementare un Percettrone molto basilare in Python.\n",
    "\n",
    "Per riscaldarci e preparare il terreno andiamo prima di tutto a scrivere la funzione di Heaviside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Heaviside(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora siamo pronti per scrivere il codice vero e proprio: utilizzeremo il paradigma ad ogetti che in questo caso permette una modellazione molto naturale. \n",
    "\n",
    "La nostra classe Perceptron avrà 4 attributi:\n",
    "- *f:* sarà la funzione di attivazione che userà il nostro percettrone, bisogna passarlo come paramentro al momento di creazione dell'ogetto\n",
    "- *weight:* è la lista dei pesi del percettrone\n",
    "- *input:* lista di input del percettrone: ad ogni input corrisponde il peso nella stessa posizione in weight\n",
    "- *output:* contiene l'ultimo output calcolato, di default 0\n",
    "\n",
    "Inoltre oltre ad  __init__ e __str__ definiremo 4 metodi:\n",
    "- *add_link(w, i):* aggiunge un nuovo link (sinapsi) di peso *w* e il rispettivo valore di input *i*\n",
    "- *set_input(inp):* sostituisce il vettore di input del percettrone con il nuovo vettore *inp*, importante controllare che le dimensioni non siano diverse\n",
    "- *process():* esegue l'eleborazione vera e propria: somma pesata (passo 1) e soglia (passo 2) e restituisce l'output\n",
    "- *get_output():* restituisce l'ultimo output calcolato\n",
    "\n",
    "Dunque ogni volta che aggiungiamo un nuovo link specifichiamo il peso e il valore del rispettivo input, il vettore di input può comunque essere cambiato con *set_input*, per il momento però possiamo cambiare l'intera lista e non il singolo valore inoltre non consentiamo l'eliminazione dei link o la modifica dei pesi, queste operazioni infatti, anche se renderebbo il codice più flessibile non aggiungono nulla a livello didattico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, f):\n",
    "        ''' \n",
    "        Initialize new Perceptron\n",
    "        params f: activation function\n",
    "        '''\n",
    "    \n",
    "        self.f = f\n",
    "        self.weight = [] #list of weights\n",
    "        self.input = [] #list of input\n",
    "        self.output = 0\n",
    "        \n",
    "    def add_link(self, w, i):\n",
    "        ''' \n",
    "        Add a link in the perceptron with input\n",
    "        params w: the weight of the link\n",
    "        params i: the value of the input\n",
    "        '''\n",
    "        self.weight.append(w)\n",
    "        self.input.append(i)\n",
    "        \n",
    "    def set_input(self, inp):\n",
    "        ''' \n",
    "        Set new input \n",
    "        params inp: array of input\n",
    "        '''\n",
    "        if len(inp) == len(self.weight):\n",
    "            self.input = inp\n",
    "\n",
    "    def process(self):\n",
    "        ''' \n",
    "        Process the input \n",
    "        '''\n",
    "        res = 0\n",
    "\n",
    "        print(\"PROCESS\")\n",
    "\n",
    "        #step 1\n",
    "        for i in range(len(self.weight)): \n",
    "            print(\"{} * {} -> {}\".format(self.input[i], self.weight[i], self.input[i]*self.weight[i]))\n",
    "            res += self.input[i]*self.weight[i]\n",
    "\n",
    "        #step 2\n",
    "        self.output = self.f(res)\n",
    "        print(\"----\\n{} -> {}\".format(res,self.output))\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def get_output(self):\n",
    "        ''' \n",
    "        return the output\n",
    "        '''\n",
    "        return self.output\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"INPUT: {}\\nWEIGHT: {}\\nOUTPUT: {}\".format(self.input,self.weight,self.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora eseguiamo un rapido test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: [-3, 2, 1]\n",
      "WEIGHT: [1, -1, 0.5]\n",
      "OUTPUT: 0\n",
      "PROCESS\n",
      "-3 * 1 -> -3\n",
      "2 * -1 -> -2\n",
      "1 * 0.5 -> 0.5\n",
      "----\n",
      "-4.5 -> 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Perceptron(Heaviside)\n",
    "\n",
    "p.add_link(1, -3)\n",
    "p.add_link(-1, 2)\n",
    "p.add_link(0.5, 1)\n",
    "\n",
    "print(p)\n",
    "p.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso proviamo a cambiare gli input e a rieseguire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: [2, -5, 0]\n",
      "WEIGHT: [1, -1, 0.5]\n",
      "OUTPUT: 0\n",
      "PROCESS\n",
      "2 * 1 -> 2\n",
      "-5 * -1 -> 5\n",
      "0 * 0.5 -> 0.0\n",
      "----\n",
      "7.0 -> 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.set_input([2,-5,0])\n",
    "\n",
    "print(p)\n",
    "p.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "$1$: Più nello specifico la rete neurale deve essere feed-forward con un solo strato nascosto, con un numero finito di neuroni e funzione di attivazione di tipo sigmoidale e un neurone di output con funzione di attivazione di tipo lineare.\n",
    "\n",
    "$2$: Non è propriamente verso, infatti non tutte le funzioni $f: R^n \\to R^m$ sono approssimabili da una rete neurale. [Dettagli](https://it.qwertyu.wiki/wiki/Universal_approximation_theorem).\n",
    "\n",
    "$3$: $f: R \\to R$ è una funzione è lineare se è esprimibile nella forma $f(x)=ax+b$ con $a$ e $b$ costanti reali. Più in generale una funzione lineare è una funzione $f$ per cui valgono le due seguenti proprietà:\n",
    "- $f(x+y) = f(x)+f(y)$\n",
    "- $f(ax) = a*f(x)$ con $a$ costante\n",
    "\n",
    "\n",
    "$4$: Un iperpiano di uno spazio vettoriale $V$ è un sotto-spazio vettoriale di $V$ di dimensione $dim(V)-1$"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
